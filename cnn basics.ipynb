{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN basics\n",
    "\n",
    "    - CNN are inspired by the biology of vision cells in cortex of mammals\n",
    "    - In a DNN each unit in one layer is connected to EACH unit in another layer\n",
    "    - In a CNN each unit in one layer is connected to FEW units in another layer\n",
    "        - Each CNN layer looks at an increasingly larger part of the image\n",
    "        - For each layer we define set of Filters\n",
    "        - Layer 1\n",
    "            - 1 Filter of shape 3*3\n",
    "            - This filter would have 9 weights\n",
    "            - This filter would be applied to 9 pixels \n",
    "            - Pixel value would be multiple by weights\n",
    "            - Output would be summed to get a scalar\n",
    "            - So output of this filter operation is a scalar\n",
    "            - Likewise we can have multiple filters in one layer\n",
    "        - Layer 2\n",
    "            - 1 Filter of shape 4*4\n",
    "            - This filter would have 16 weights\n",
    "            - This filter would be applied to 16 pixels \n",
    "            - Pixel value would be multiple by weights\n",
    "            - Output would be summed to get a scalar\n",
    "            - So output of this filter operation is a scalar\n",
    "            - Likewise we can have multiple filters in one layer\n",
    "        - We can stack multiple layers of CNN with multiple filters with multiple dimensions. However on a given layer each filter would be of the same dimension\n",
    "        \n",
    "        - Concept of Strides\n",
    "            - Strides would be of a value N, say 2\n",
    "            - In convolusion layer say we have a filter of dimension 3*3\n",
    "            - Say an input image has shape 10*10 pixels, think of it as a matrix for understanding\n",
    "            - Filter would read first 3 pixels on x-axis (& 3 on y), with stride as 1, it would then read next 3 pixels from 1st pixel\n",
    "            - Filter would read first 3 pixels on x-axis (& 3 on y), with stride as 2, it would then read next 3 pixels from 3rd pixel\n",
    "            - Filter would read first 3 pixels on x-axis (& 3 on y), with stride as 3, it would then read next 3 pixels from 4th pixel\n",
    "            \n",
    "        - Concept of Pooling layer\n",
    "            - Say an input image has shape 10*10 pixels, think of it as a matrix for understanding\n",
    "            - A pooling layer also has filters of say size 2*2\n",
    "            - Say stride is 2\n",
    "            - Now, filter would read first 2 pixels on x-axis (& 2 on y) - find the max value of those pixels and extract that\n",
    "            - Filter then uses stride to then read next set of filters and finds next max value\n",
    "            - This way Pooling layer reduces the amount of data it needs to process\n",
    "            \n",
    "        - Famous CNN networks like RosNet, GoogleNet are basically a CNN architecture with following components\n",
    "            - 1 or more convolusion layers\n",
    "                - Each convolusion layer with 1 or more Filters and defined Stride\n",
    "            - 1 or more pooling layers\n",
    "                - Each convolusion layer with 1 or more Filters and defined Stride\n",
    "            - So a RahulNet could be like this:\n",
    "                - 1 CN layer, 2 Filters (3*3), Stride (2)\n",
    "                - 1 Pooling layer, 2 Filters (3*3), Stride (2)\n",
    "                - 1 CN layer, 5 Filters (2*2), Stride (3)\n",
    "                - 1 Pooling layer, 5 Filters (2*2), Stride (3)\n",
    "                - Final Dense layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Filters, Kerners & Input Shape\n",
    "\n",
    "    - Consider example below\n",
    "    - Here we are doing the following:\n",
    "        - creating one layer of Conv2D \n",
    "        - Number of filters is 200; which means we have 200 filters which would be identifying a particular shape\n",
    "        - Each filter has kernel of 3; which means (3*3*1)\n",
    "        - Input shape is (28,28,1); which means that the data is a Rank 3 tensor\n",
    "        - Number of parameters this layer has to estimate is:\n",
    "            - 200 * (3*3*1+1) which is 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - model.add(Conv2D(filters=200, kernel_size=3, strides=(1,1), activation='relu', input_shape=(28,28,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tips: \n",
    "        - When using Conv & MaxPooling the depth of feature map would increase through layers and length of feature map would reduce. This should be a good pattern when you do summary.\n",
    "        - Each Conv2D layer accepts a Rank 3 tensor\n",
    "        - Layer 1 which accepts image which is represented as Rank 3 tensor (Height, Weight, Channel)\n",
    "        - Each layer takes input a tensor and outputs a tensor\n",
    "        - Number of filters in any layer would determine the channels in the output tensor. For e.g. if a layer has 10 filters then it's output tensor would have 10 channels, like (?,?,10)\n",
    "        - Filters in convulation layers have two specific advantages:\n",
    "            - Filters learn localized representation of images; for e.g. an edge, a line, ear, nose etc. Since they learn local patterns they can apply those learnings when they see those patterns again.\n",
    "            - In a MLP layer, all inputs are understood as once hence the reusability when presented with new data becomes zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
